{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08acf90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering\n",
    "\n",
    "##### PWSA2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17727571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "* Previously, we’ve seen examples of supervised learning where we had $\\textbf{x}_n$ and associated target labels tn\n",
    "\n",
    "\n",
    "* What if we only have $\\textbf{x}_n$? \n",
    "\n",
    "\n",
    "* Objects with a list of characteristics: can we group the objects based on their characteristics?\n",
    "\n",
    "\n",
    "* This is known as clustering and is an example of unsupervised learning\n",
    "\n",
    "\n",
    "* Another example of unsupervised learning is projection/dimensionality reductions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c33f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "* Hierarchical clustering \n",
    "\n",
    "* K-means \n",
    "\n",
    "* Mixture models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817baa36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hierarchical clustering \n",
    "\n",
    "* Join the two most similar objects\n",
    "* Join the compound object with other\n",
    "* Can cut the dendrogram to get a number of clusters\n",
    "\n",
    "<img src=\"imgs/dendrogram.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761fcd7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hierarchical clustering: define similarity?\n",
    "\n",
    "Let us have two groups of objects\n",
    "    * Single linkage: lowest pairwise distance\n",
    "    * Complete linkage: highest pairwise distance\n",
    "    * Group average: average distance\n",
    "\n",
    "\n",
    "<img src=\"imgs/distances.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1299ed7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hierarchical clustering \n",
    "\n",
    "**Pros**\n",
    "* Easy to implement\n",
    "* Data driven\n",
    "* Flexible in getting number of clusters\n",
    "\n",
    "**Cons**\n",
    "* Sensitive to the data points\n",
    "* Cannot add a new data point to a cluster → as the dendrogram is going to change\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f969b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means\n",
    "\n",
    "* We are going to adopt a slightly different approach\n",
    "\n",
    "\n",
    "* Instead of having a data-driven approach, we are going to create a model of a cluster\n",
    "\n",
    "\n",
    "* Clusters are defined by their centre; a centre is defined as the mean of the objects in that cluster\n",
    "\n",
    "\n",
    "* We assign object to their closest cluster\n",
    "\n",
    "\n",
    "* Circular argument: what came first chicken or the egg?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b03972",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means\n",
    "\n",
    "* Iterative approach\n",
    "* Algorithm overview: \n",
    "    1. Guess the means\n",
    "    2. Assign objects to clusters\n",
    "    3. Re-compute means\n",
    "    4. Go back to 2\n",
    "\n",
    "We keep doing this until objects stop being reassigned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dd3bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: an example\n",
    "\n",
    "* Cluster means are randomly assigned (top left corner)\n",
    "* Points assigned to their closest mean\n",
    "\n",
    "<img src=\"imgs/kmeans1.png\" width=350 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2acf07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: an example\n",
    "\n",
    "Update cluster means to match assigned points \n",
    "\n",
    "<img src=\"imgs/kmeans2.png\" width=350 />\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40723dde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means : an example\n",
    "\n",
    "Points re-assigned to closest mean\n",
    "\n",
    "<img src=\"imgs/kmeans3.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190234ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: an example \n",
    "\n",
    "Cluster means updated to mean of the assigned points\n",
    "\n",
    "<img src=\"imgs/kmeans4.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d052c5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: an example\n",
    "\n",
    "Update point assignment\n",
    "\n",
    "<img src=\"imgs/kmeans5.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e538e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: and after a few rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff304449",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means: at convergence \n",
    "\n",
    "<img src=\"imgs/kmeans6.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885a836",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing K\n",
    "\n",
    "* Tricky!\n",
    "\n",
    "* Sometimes you have ground truth. E.g Adjusted rand index\n",
    "\n",
    "* Metrics for how well an object is matched to its own cluster compared to neighbouring clusters e.g Silhouette plots\n",
    "\n",
    "* Domain knowledge is important! How many clusters of patients/images/cell types do you expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51b343",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kernalised K-means \n",
    "\n",
    "* Standard K-means won’t work here. Why? What are the means of the two circles?\n",
    "* Same ideas as SVM\n",
    "\n",
    "<img src=\"imgs/kernelkmeans.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ad931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means\n",
    "\n",
    "**Pros**\n",
    "* Simple to implement\n",
    "* Very few assumptions\n",
    "* Can be kernalised\n",
    "\n",
    "**Cons**\n",
    "* Hard assignment to a cluster\n",
    "* How do you choose K?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0d543",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models: a generative model\n",
    "\n",
    "* Probabilistic\n",
    "\n",
    "* Each cluster is now a probability distribution\n",
    "\n",
    "* Each object comes from one of different K distributions\n",
    "\n",
    "* Iterative approach: \n",
    "  1. Guess the parameter of the distribution\n",
    "  2. Compute probabilities of object cluster membership\n",
    "  3. Update the distribution parameters (based on soft assignment)\n",
    "  4. Go to 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853ed67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models\n",
    "\n",
    "Initial parameter values\n",
    "\n",
    "<img src=\"imgs/mixtures1.png\" width=350 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21015d6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models\n",
    "\n",
    "<img src=\"imgs/mixtures2.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1885bfc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models\n",
    "\n",
    "<img src=\"imgs/mixtures3.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bced6df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models\n",
    "\n",
    "<img src=\"imgs/mixtures4.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae14db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models\n",
    "\n",
    "At convergence \n",
    "\n",
    "<img src=\"imgs/mixtures5.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f11fe1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixture models \n",
    "\n",
    "**Pros**\n",
    "* Flexible \n",
    "* Probabilistic\n",
    "* Can set K by cross-validation\n",
    "\n",
    "**Cons**\n",
    "* More demanding than K-means\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5ca47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beyond mixture models\n",
    "\n",
    "* So we looked at mixture models and the idea that we model complex distributions as combinations of simpler ones\n",
    "\n",
    "\n",
    "\n",
    "* Main assumption of mixture models: each data point is generated by one particular mixture component \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057c413",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"imgs/topics1.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b51e70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"imgs/topics2.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd16ce4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"imgs/topics3.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9bf54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"imgs/topics4.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3243a6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic Models\n",
    "\n",
    "* Generative model\n",
    "\n",
    "* Each component is a topic \n",
    "\n",
    "* A document has contribution from multiple topics\n",
    "\n",
    "* A topic: a group of words \n",
    "        \n",
    "* Words can belong to multiple topics!\n",
    "\n",
    "* Applications beyond text! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ed116",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenges\n",
    "\n",
    "* You need to specify the number of topics:\n",
    "    * How many do we choose? \n",
    "    \n",
    "* How do we interpret our topics? \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
